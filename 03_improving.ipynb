{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Inspired by and borrowed heavily from: Collective Intelligence - [Luís F. Simões](mailto:luis.simoes@vu.nl).\n",
    "IR version and assignments by J.E. Hoeksema, 2014-11-12.\n",
    "Converted to Python 3 and minor changes by Tobias Kuhn, 2015-10-11.)_\n",
    "\n",
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's purpose is to improve the search index and query functions built in the previous notebook and assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data, Defining some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is copied from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle, bz2, re\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "from IPython.display import display, HTML\n",
    "from math import log10\n",
    "\n",
    "Summaries_file = 'data/evolution__Summaries.pkl.bz2'\n",
    "Abstracts_file = 'data/evolution__Abstracts.pkl.bz2'\n",
    "\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )\n",
    "    \n",
    "def display_summary( id, extra_text='' ): # For a non-notebook version: see the Discussion Board\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long titles or author lists, and links to the paper's  DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[ id ]\n",
    "    \n",
    "    title = ( s.title if s.title[-1]!='.' else s.title[:-1] )\n",
    "    title = title[:150].rstrip() + ('' if len(title)<=150 else '...')\n",
    "    if s.doi!='':\n",
    "        title = '<a href=http://dx.doi.org/%s>%s</a>' % (s.doi, title)\n",
    "    \n",
    "    authors = ', '.join( s.authors[:5] ) + ('' if len(s.authors)<=5 else ', ...')\n",
    "    \n",
    "    lines = [\n",
    "        title,\n",
    "        authors,\n",
    "        str(s.year),\n",
    "        '<small>id: %d%s</small>' % (id, extra_text)\n",
    "        ]\n",
    "    \n",
    "    display( HTML( '<blockquote>%s</blockquote>' % '<br>'.join(lines) ) )\n",
    "    \n",
    "def display_abstract( id, highlights=[]): # For a non-notebook version: see the Discussion Board\n",
    "    \"\"\"\n",
    "    Function for displaying an abstract. Includes optional (naive) highlighting\n",
    "    \"\"\"\n",
    "    a = Abstracts[ id ]\n",
    "    for h in highlights:\n",
    "        a = re.sub(r'\\b(%s)\\b'%h,'<mark>\\\\1</mark>',a, flags=re.IGNORECASE)\n",
    "    display( HTML( '<blockquote>%s</blockquote' % a ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
    "    \"\"\"\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(set)\n",
    "\n",
    "# Takes a while\n",
    "for (id, abstract) in Abstracts.items():\n",
    "    for term in preprocess(tokenize(abstract)):\n",
    "        inverted_index[term].add(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Short (one-liner) versions of and_query and or_query\n",
    "def or_query(query):\n",
    "    return reduce(lambda a, e: a.union(e), [inverted_index[term] for term in preprocess(tokenize(query))])\n",
    "\n",
    "def and_query(query): \n",
    "    return reduce(lambda a, e: a.intersection(e), [inverted_index[term] for term in preprocess(tokenize(query))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see from the results of the last assignment, our simple index doesn't handle punctuation and the difference between singular and plural versions of the same word very well. A possible solution to those issues would be to apply better tokenization and stemming. Fortunately, Python's *NLTK* package provides implementations of these algorithms we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tk/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "['Good', 'muffins', 'cost', '$3.88\\nin', 'New', 'York.', '', 'Please', 'buy', 'me', 'two', 'of', 'them.\\n\\nThanks.']\n",
      "['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
    "\n",
    "print(tokenize(s))\n",
    "print(word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"processes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to improve our search results is to *rank* them. A possible way to do this is to calculate a score for each document based on the matching terms from the query. One such scoring method is *tf.idf*, as explained in the slides from Lecture 5.\n",
    "\n",
    "In order to quickly calculate the scores for a term/document combination, we'll need quick access to a couple of things:\n",
    "* tf(t,d) - How often does a term occur in a document\n",
    "* df(t) - In how many documents does a term occur\n",
    "* N - The number of documents in our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "tf_matrix = defaultdict(Counter)\n",
    "for (id, abstract) in Abstracts.items():\n",
    "    tf_matrix[id] = Counter(preprocess(tokenize(abstract)))\n",
    "\n",
    "def tf(t,d):\n",
    "    return float(tf_matrix[d][t])\n",
    "\n",
    "def df(t):\n",
    "    return float(len(inverted_index[t]))\n",
    "    \n",
    "def num_documents():\n",
    "    return float(len(Abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "128206.0\n",
      "205343.0\n"
     ]
    }
   ],
   "source": [
    "print(tf('evolution',23144668))\n",
    "print(df('evolution'))\n",
    "print(num_documents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these three helper functions, we can now easily calculate the tf.idf weights of a term in a document by implementing the weighting formula from the slides, which you will do in the assignments below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change (in the code cell below) the *smarter_tokenize* function to use NLTK's word_tokenize function for tokenization, and the *smarter_preprocess* function to perform stemming in addition to case normalization. Does `smarter_and_query(\"evolutionary process\")` return our example paper *23144668*? Why (not)?\n",
    "\n",
    "  <small>We are purposely generating this index on a subset of the data, as generating an index with stemming on the entire set would take up to half an hour</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{23197827, 23185476, 23133349, 23138755, 23194053, 23193289, 23192074, 23148266, 23198988, 23100716, 23188590, 23168079, 23166479, 23188175, 23132463, 23116822, 23106710, 23179131, 23135324, 23106717, 23136734}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def smarter_tokenize(text):\n",
    "    # Change this\n",
    "    return text.split(' ')\n",
    "\n",
    "def smarter_preprocess(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        # Change this\n",
    "        result.append(token.lower())\n",
    "    return result\n",
    "\n",
    "def smarter_and_query(query): # Regular and_query using smarter_tokenize and smarter_preprocess\n",
    "    return reduce(lambda a, e: a.intersection(e), [smarter_index[term] for term in smarter_preprocess(smarter_tokenize(query))])\n",
    "\n",
    "smarter_index = defaultdict(set)\n",
    "# Create a subset of around 1400 document IDs\n",
    "subset = set(Abstracts.keys()).intersection(set(range(23100000,23200000)))\n",
    "\n",
    "for (id, abstract) in ((k, Abstracts[k]) for k in subset):\n",
    "    for term in smarter_preprocess(smarter_tokenize(abstract)):\n",
    "        smarter_index[term].add(id)\n",
    "        \n",
    "print(smarter_and_query(\"evolutionary process\"))\n",
    "print(23144668 in smarter_and_query(\"evolutionary process\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function `tfidf(t,d)` that returns the tf.idf score of term `t` in document `d` by using the `tf(t,d)`, `df(t)` and `num_documents()` functions we defined above. The tf.idf formula can be found on the slides for Lecture 5.\n",
    "  \n",
    "  <small>You can use the `log10(n)` function to calculate log<sub>10</sub>(n), and you can use the code cell below to verify your results.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print tfidf('embodied',23144668) # 3.35343851032\n",
    "#print tfidf('evolution',23144668) # 0.302176987782\n",
    "#print tfidf('notinthedocument',23144668) # 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function `query(query_string)`, which accepts as input a single query string that could consist of one or more words, and returns or prints a list of (up to) 10 best matching documents, along with their score. \n",
    "\n",
    "  You should use tf.idf to calculate document scores based on the query, and the results should be ordered by score in descending order.\n",
    "\n",
    "  <small>Hint: Start by copying your `or_query` function from mini-assignment 2, then expand that to rank the results, making use of the `tfidf(t,d)` function you created earlier.</small>\n",
    "\n",
    "  <small>You can either return or print a list of (id, score) tuples, or use the provided `display_summary(id,extra_text)` function to make the output a bit more 'search engine'-like. Both are valid for completing the assignment.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Come up with a few example queries to run, and include the output here. Do the results make sense? Why (not)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
